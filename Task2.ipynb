{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aquib-Nawaz/End-to-End-ASR-using-Transfer-Learning/blob/main/Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45ea3ef5"
      },
      "source": [
        "# Easy transfer learning with 🐸 STT ⚡\n",
        "\n",
        "You want to train a Coqui (🐸) STT model, but you don't have a lot of data. What do you do?\n",
        "\n",
        "The answer 💡: Grab a pre-trained model and fine-tune it to your data. This is called `\"Transfer Learning\"` ⚡\n",
        "\n",
        "🐸 STT comes with transfer learning support out-of-the box.\n",
        "\n",
        "You can even take a pre-trained model and fine-tune it to _any new language_, even if the alphabets are completely different. Likewise, you can fine-tune a model to your own data and improve performance if the language is the same.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Download a pre-trained English STT model.\n",
        "2. Download data for the Marathi language.\n",
        "3. Fine-tune the English model to Russian language.\n",
        "4. Test the new Marathi model and display its performance on train and test set.\n",
        "5. Train the model after channging parameters to get better CER on test set.\n",
        "6. Display the new result.\n",
        "So, let's jump right in!\n",
        "\n",
        "*PS - If you just want a working, off-the-shelf model, check out the [🐸 Model Zoo](https://www.coqui.ai/models)*"
      ],
      "id": "45ea3ef5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa2aec77",
        "outputId": "7e340c2c-4c6e-4762-b00d-0b6955414e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (22.0.4)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: coqui_stt_training in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: tensorflow==1.15.4 in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (1.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (2.23.0)\n",
            "Requirement already satisfied: coqpit in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (0.0.15)\n",
            "Requirement already satisfied: opuslib==2.0.0 in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (2.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (1.3.5)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (0.2.2)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (3.38.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (0.10.3.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (4.64.0)\n",
            "Requirement already satisfied: semver in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (2.13.0)\n",
            "Requirement already satisfied: attrdict in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (1.15.0)\n",
            "Requirement already satisfied: webdataset in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (0.2.5)\n",
            "Requirement already satisfied: miniaudio in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (1.46)\n",
            "Requirement already satisfied: sox in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (1.4.1)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (2.10.0)\n",
            "Requirement already satisfied: coqui-stt-ctcdecoder==1.3.0 in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (1.3.0)\n",
            "Requirement already satisfied: numba<=0.53.1 in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (0.51.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (0.0.1)\n",
            "Requirement already satisfied: pyogg>=0.6.14a1 in /usr/local/lib/python3.7/dist-packages (from coqui_stt_training) (0.6.14a1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (1.15.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (0.37.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (3.17.3)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (1.44.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (1.0.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->coqui_stt_training) (0.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba<=0.53.1->coqui_stt_training) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba<=0.53.1->coqui_stt_training) (57.4.0)\n",
            "Requirement already satisfied: scipy>=0.13 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->coqui_stt_training) (1.4.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->coqui_stt_training) (4.6.3)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from miniaudio->coqui_stt_training) (1.15.0)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna->coqui_stt_training) (3.10.1)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna->coqui_stt_training) (1.7.7)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna->coqui_stt_training) (6.6.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna->coqui_stt_training) (3.13)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna->coqui_stt_training) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna->coqui_stt_training) (21.3)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna->coqui_stt_training) (1.4.35)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->coqui_stt_training) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->coqui_stt_training) (2.8.2)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->coqui_stt_training) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->coqui_stt_training) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->coqui_stt_training) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->coqui_stt_training) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->coqui_stt_training) (2021.10.8)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.7/dist-packages (from webdataset->coqui_stt_training) (0.1.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12.0->miniaudio->coqui_stt_training) (2.21)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->coqui_stt_training) (3.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna->coqui_stt_training) (3.0.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->coqui_stt_training) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->coqui_stt_training) (4.11.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->coqui_stt_training) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->coqui_stt_training) (3.3.6)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->coqui_stt_training) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna->coqui_stt_training) (5.6.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->coqui_stt_training) (3.2.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->coqui_stt_training) (5.8.1)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->coqui_stt_training) (0.5.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->coqui_stt_training) (2.4.1)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->coqui_stt_training) (3.5.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->coqui_stt_training) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->coqui_stt_training) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->coqui_stt_training) (4.1.1)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->coqui_stt_training) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna->coqui_stt_training) (3.8.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4->coqui_stt_training) (1.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna->coqui_stt_training) (2.0.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "## Install Coqui STT\n",
        "! pip install -U pip\n",
        "! pip install coqui_stt_training"
      ],
      "id": "fa2aec77"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c07a273"
      },
      "source": [
        "## ✅ Download pre-trained English model\n",
        "\n",
        "We're going to download a very small (but very accurate) pre-trained STT model for English. This model was trained to only transcribe the English words \"yes\" and \"no\", but with transfer learning we can train a new model which could transcribe any words in any language. In this notebook, we will turn this \"constrained vocabulary\" English model into an \"open vocabulary\" Russian model.\n",
        "\n",
        "Coqui STT models as typically stored as checkpoints (for training) and protobufs (for deployment). For transfer learning, we want the **model checkpoints**.\n"
      ],
      "id": "8c07a273"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "608d203f",
        "outputId": "bdd7434f-0718-4e17-fc75-0053d9e4e675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found \"english/coqui-yesno-checkpoints\" - not extracting.\n"
          ]
        }
      ],
      "source": [
        "### Download pre-trained model\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "from coqui_stt_training.util.downloader import maybe_download\n",
        "\n",
        "def download_pretrained_model():\n",
        "    model_dir=\"english/\"\n",
        "    if not os.path.exists(\"english/coqui-yesno-checkpoints\"):\n",
        "        maybe_download(\"model.tar.gz\", model_dir, \"https://github.com/coqui-ai/STT-models/releases/download/english%2Fcoqui%2Fyesno-v0.0.1/coqui-yesno-checkpoints.tar.gz\")\n",
        "        print('\\nNo extracted pre-trained model found. Extracting now...')\n",
        "        tar = tarfile.open(\"english/model.tar.gz\")\n",
        "        tar.extractall(\"english/\")\n",
        "        tar.close()\n",
        "    else:\n",
        "        print('Found \"english/coqui-yesno-checkpoints\" - not extracting.')\n",
        "\n",
        "# Download + extract pre-trained English model\n",
        "download_pretrained_model()"
      ],
      "id": "608d203f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed9dd7ab"
      },
      "source": [
        "## ✅ Download data for Russian\n",
        "\n",
        "**First things first**: we need some data.\n",
        "\n",
        "We're training a Speech-to-Text model, so we need some _speech_ and we need some _text_. Specificially, we want _transcribed speech_. Let's download a Russian audio file and its transcript, pre-formatted for 🐸 STT. \n",
        "\n",
        "**Second things second**: we want a Russian alphabet. The output layer of a typical* 🐸 STT model represents letters in the alphabet. Let's download a Russian alphabet from Coqui and use that.\n",
        "\n",
        "*_If you are working with languages with large character sets (e.g. Chinese), you can set `bytes_output_mode=True` instead of supplying an `alphabet.txt` file. In this case, the output layer of the STT model will correspond to individual UTF-8 bytes instead of individual characters._"
      ],
      "id": "ed9dd7ab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5105ea7",
        "outputId": "40aa5ef9-6642-4879-c9f9-eaa4baa69a7e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found archive \"./ml-data.tar.gz\" - not downloading.\n"
          ]
        }
      ],
      "source": [
        "### Download sample data\n",
        "from coqui_stt_training.util.downloader import maybe_download\n",
        "\n",
        "def download_sample_data():\n",
        "#     data_dir=\"data/\"\n",
        "        #https://www.cse.iitb.ac.in/~pjyothi/cs753/data.tgz\n",
        "    maybe_download(\"ml-data.tar.gz\", \"./\", \"https://www.cse.iitb.ac.in/~pjyothi/cs753/ml-data.tgz\")\n",
        "    tar = tarfile.open(\"ml-data.tar.gz\")\n",
        "    tar.extractall(\"./\")\n",
        "\n",
        "# Download sample Russian data\n",
        "download_sample_data()"
      ],
      "id": "b5105ea7"
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "def download_generatescorer():\n",
        "#     data_dir=\"data/\"\n",
        "        #https://www.cse.iitb.ac.in/~pjyothi/cs753/data.tgz\n",
        "    maybe_download(\"native_client.tflite.Linux.tar.xz3.07\", \"./\", \"https://github.com/coqui-ai/STT/releases/download/v1.3.0/native_client.tflite.Linux.tar.xz\")\n",
        "    tar = tarfile.open(\"native_client.tflite.Linux.tar.xz3.07\")\n",
        "    tar.extractall(\"native_client.tflite.Linux/\")\n",
        "    tar.close()\n",
        "\n",
        "\n",
        "# Download sample Russian data\n",
        "download_generatescorer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRSF8W5qIjNS",
        "outputId": "20fc404c-e68f-43e8-cdf2-61f202b35314"
      },
      "id": "QRSF8W5qIjNS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found archive \"./native_client.tflite.Linux.tar.xz3.07\" - not downloading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "f = open('ml-data/telugu-alphabet.txt', 'w', encoding=\"utf8\")\n",
        "f.write(' \\nఀ\\nఁ\\n ం\\n ః\t\\nఅ\\nఆ\\nఇ\\nఈ\\nఉ\\nఊ\\nఋ\\nఌ\\nఎ\\nఏ\\nఐ\\nఒ\\nఓ\\nఔ\\nక\\nఖ\\nగ\\nఘ\\nఙ\\nచ\\nఛ\\nజ\\nఝ\\nఞ\\nట\\nఠ\\nడ\\nఢ\\nణ\\nత\\nథ\\nద\\nధ\\nన\\nప\\nఫ\\nబ\\nభ\\nమ\\nయ\\nర\\nఱ\\nల\\nళ\\nఴ\\nవ\\nశ\\nష\\nస\\nహ\\nఽ\\nా\\nి\\nీ\\nు\\nూ\\nృ\\nౄ\\nె\\nే\\nై\\nొ\\nో\\nౌ\\n్\\nౕ\\nౖ\\nౘ\\nౙ\\nౚ\\nౠ\\nౡ\\nౢ\\nౣ\\n౦\\n౧\\n౨\\n౩\\n౪\\n౫\\n౬\\n౭\\n౮\\n౯\\n౸\\n౹\\n౺\\n౻\\n౼\\n౽\\n౾\\n౿\\nం\\n\\\\\\nn')\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "id": "6FpRSEP57yHa"
      },
      "id": "6FpRSEP57yHa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QKrLsQI5TNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efcb6d73-00a9-444f-ae87-308d43b7f317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘ml-data/checkpoints’: File exists\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "f = open('ml-data/kannada-alphabet.txt', 'w', encoding=\"utf8\")\n",
        "! mkdir ml-data/checkpoints\n",
        "f1 = open('ml-data/checkpoints/alphabet.txt','w',encoding=\"utf8\")\n",
        "f.write(' \\nಅ\\nಆ\\nಇ\\nಈ\\nಉ\\nಊ\\nಋ\\nೠ\\nಎ\\nಏ\\nಐ\\nಒ\\nಓ\\nಔ\\nಅಂ\\nಅಃ\\nಕ\\nಖ\\nಗ\\nಘ\\nಙ\\nಚ\\nಛ\\nಜ\\nಝ\\nಞ\\nಜ಼\\nಟ\\nಠ\\nಡ\\nಢ\\nಣ\\nತ\\nಥ\\nದ\\nಧ\\nನ\\nಪ\\nಫ\\nಬ\\nಭ\\nಮ\\nಫ಼\\nಯ\\nರ\\nಱ\\nಲ\\nಳ\\nೞ\\nವ\\nಶ\\nಷ\\nಸ\\nಹ\\nಾ\\nಿ\\nೀ\\nು\\nೂ\\nೃ\\nೄ\\nೆ\\nೇ\\n ೈ\\nೊ\\nೋ\\nೌ\\nಂ\\nಃ\\n್\\n.\\nೈ\\n')\n",
        "f1.write(' \\nಅ\\nಆ\\nಇ\\nಈ\\nಉ\\nಊ\\nಋ\\nೠ\\nಎ\\nಏ\\nಐ\\nಒ\\nಓ\\nಔ\\nಅಂ\\nಅಃ\\nಕ\\nಖ\\nಗ\\nಘ\\nಙ\\nಚ\\nಛ\\nಜ\\nಝ\\nಞ\\nಜ಼\\nಟ\\nಠ\\nಡ\\nಢ\\nಣ\\nತ\\nಥ\\nದ\\nಧ\\nನ\\nಪ\\nಫ\\nಬ\\nಭ\\nಮ\\nಫ಼\\nಯ\\nರ\\nಱ\\nಲ\\nಳ\\nೞ\\nವ\\nಶ\\nಷ\\nಸ\\nಹ\\nಾ\\nಿ\\nೀ\\nು\\nೂ\\nೃ\\nೄ\\nೆ\\nೇ\\n ೈ\\nೊ\\nೋ\\nೌ\\nಂ\\nಃ\\n್\\n.\\nೈ\\n')\n",
        "f.close()\n",
        "f1.close()"
      ],
      "id": "5QKrLsQI5TNe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b46b7227"
      },
      "source": [
        "## ✅ Configure the training run\n",
        "\n",
        "Making `ma.csv` training file and `matest.csv` test file from `marathi.tsv`"
      ],
      "id": "b46b7227"
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('ml-data/tg.csv','w')\n",
        "f.write('wav_filename,wav_filesize,transcript\\n')\n",
        "f2 = open('ml-data/tgdev.csv', 'w')\n",
        "f2.write('wav_filename,wav_filesize,transcript\\n')\n",
        "with open('ml-data/train.tsv', 'r') as rfile:\n",
        "    lines = rfile.readlines()\n",
        "    for l in lines[10:15]:\n",
        "        l_ = l.split('\\t')\n",
        "        f.write('train/telugu/'+l_[0]+'.wav,0,'+l_[1])\n",
        "    for l in lines[15:20]:\n",
        "        l_ = l.split('\\t')\n",
        "        f2.write('train/telugu/'+l_[0]+'.wav,0,'+l_[1])\n",
        "f.close()\n",
        "f2.close()"
      ],
      "metadata": {
        "id": "wnjQxBuP8M-B"
      },
      "id": "wnjQxBuP8M-B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_AvzmzRW7Bg"
      },
      "source": [
        "Initialize the model configuration. It is same as given with changed file name."
      ],
      "id": "V_AvzmzRW7Bg"
    },
    {
      "cell_type": "code",
      "source": [
        "from coqui_stt_training.util.config import initialize_globals_from_args\n",
        "\n",
        "initialize_globals_from_args(\n",
        "    n_hidden=64,\n",
        "    load_checkpoint_dir=\"english/coqui-yesno-checkpoints\",\n",
        "    save_checkpoint_dir=\"ml-data/telugu/checkpoints\",\n",
        "    drop_source_layers=1,\n",
        "    alphabet_config_path=\"ml-data/telugu-alphabet.txt\",\n",
        "    train_files=[\"ml-data/tg.csv\"],\n",
        "    dev_files=[\"ml-data/tgdev.csv\"],\n",
        "    epochs=100,\n",
        "    load_cudnn=True,\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "5wPIOvzK8s6t"
      },
      "id": "5wPIOvzK8s6t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "419828c1"
      },
      "source": [
        "### View all Config settings (*Optional*) "
      ],
      "id": "419828c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cac6ea3d",
        "outputId": "00892833-a458-40bd-e51b-612cad1939f9",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"train_files\": [\n",
            "        \"ml-data/tg.csv\"\n",
            "    ],\n",
            "    \"dev_files\": [\n",
            "        \"ml-data/tgdev.csv\"\n",
            "    ],\n",
            "    \"test_files\": [],\n",
            "    \"metrics_files\": [],\n",
            "    \"auto_input_dataset\": \"\",\n",
            "    \"vocab_file\": \"\",\n",
            "    \"read_buffer\": 1048576,\n",
            "    \"feature_cache\": \"\",\n",
            "    \"cache_for_epochs\": 0,\n",
            "    \"shuffle_batches\": false,\n",
            "    \"shuffle_start\": 1,\n",
            "    \"shuffle_buffer\": 1000,\n",
            "    \"feature_win_len\": 32,\n",
            "    \"feature_win_step\": 20,\n",
            "    \"audio_sample_rate\": 16000,\n",
            "    \"normalize_sample_rate\": true,\n",
            "    \"augment\": null,\n",
            "    \"epochs\": 100,\n",
            "    \"dropout_rate\": 0.05,\n",
            "    \"dropout_rate2\": 0.05,\n",
            "    \"dropout_rate3\": 0.05,\n",
            "    \"dropout_rate4\": 0.0,\n",
            "    \"dropout_rate5\": 0.0,\n",
            "    \"dropout_rate6\": 0.05,\n",
            "    \"relu_clip\": 20.0,\n",
            "    \"beta1\": 0.9,\n",
            "    \"beta2\": 0.999,\n",
            "    \"epsilon\": 1e-08,\n",
            "    \"learning_rate\": 0.001,\n",
            "    \"train_batch_size\": 1,\n",
            "    \"dev_batch_size\": 1,\n",
            "    \"test_batch_size\": 1,\n",
            "    \"export_batch_size\": 1,\n",
            "    \"inter_op_parallelism_threads\": 0,\n",
            "    \"intra_op_parallelism_threads\": 0,\n",
            "    \"use_allow_growth\": false,\n",
            "    \"load_cudnn\": true,\n",
            "    \"train_cudnn\": false,\n",
            "    \"automatic_mixed_precision\": false,\n",
            "    \"limit_test\": 0,\n",
            "    \"reverse_test\": false,\n",
            "    \"checkpoint_dir\": \"\",\n",
            "    \"load_checkpoint_dir\": \"english/coqui-yesno-checkpoints\",\n",
            "    \"save_checkpoint_dir\": \"ml-data/telugu/checkpoints\",\n",
            "    \"checkpoint_secs\": 600,\n",
            "    \"max_to_keep\": 5,\n",
            "    \"load_train\": \"auto\",\n",
            "    \"load_evaluate\": \"auto\",\n",
            "    \"drop_source_layers\": 1,\n",
            "    \"export_dir\": \"\",\n",
            "    \"remove_export\": false,\n",
            "    \"export_tflite\": true,\n",
            "    \"export_quantize\": true,\n",
            "    \"export_savedmodel\": false,\n",
            "    \"n_steps\": 16,\n",
            "    \"export_zip\": false,\n",
            "    \"export_file_name\": \"output_graph\",\n",
            "    \"export_beam_width\": 500,\n",
            "    \"export_author_id\": \"author\",\n",
            "    \"export_model_name\": \"model\",\n",
            "    \"export_model_version\": \"0.0.1\",\n",
            "    \"export_contact_info\": \"<public contact information of the author. Can be an email address, or a link to a contact form, issue tracker, or discussion forum. Must provide a way to reach the model authors>\",\n",
            "    \"export_license\": \"<SPDX identifier of the license of the exported model. See https://spdx.org/licenses/. If the license does not have an SPDX identifier, use the license name.>\",\n",
            "    \"export_language\": \"<language the model was trained on - IETF BCP 47 language tag including at least language, script and region subtags. E.g. \\\"en-Latn-UK\\\" or \\\"de-Latn-DE\\\" or \\\"cmn-Hans-CN\\\". Include as much info as you can without loss of precision. For example, if a model is trained on Scottish English, include the variant subtag: \\\"en-Latn-GB-Scotland\\\".>\",\n",
            "    \"export_min_stt_version\": \"<minimum Coqui STT version (inclusive) the exported model is compatible with>\",\n",
            "    \"export_max_stt_version\": \"<maximum Coqui STT version (inclusive) the exported model is compatible with>\",\n",
            "    \"export_description\": \"<Freeform description of the model being exported. Markdown accepted. You can also leave this flag unchanged and edit the generated .md file directly. Useful things to describe are demographic and acoustic characteristics of the data used to train the model, any architectural changes, names of public datasets that were used when applicable, hyperparameters used for training, evaluation results on standard benchmark datasets, etc.>\",\n",
            "    \"log_level\": 1,\n",
            "    \"show_progressbar\": true,\n",
            "    \"log_placement\": false,\n",
            "    \"report_count\": 5,\n",
            "    \"summary_dir\": \"ml-data/telugu/checkpoints/summaries\",\n",
            "    \"test_output_file\": \"\",\n",
            "    \"n_hidden\": 64,\n",
            "    \"layer_norm\": false,\n",
            "    \"random_seed\": 4568,\n",
            "    \"early_stop\": false,\n",
            "    \"es_epochs\": 25,\n",
            "    \"es_min_delta\": 0.05,\n",
            "    \"reduce_lr_on_plateau\": false,\n",
            "    \"plateau_epochs\": 10,\n",
            "    \"plateau_reduction\": 0.1,\n",
            "    \"force_initialize_learning_rate\": false,\n",
            "    \"bytes_output_mode\": false,\n",
            "    \"alphabet_config_path\": \"ml-data/telugu-alphabet.txt\",\n",
            "    \"scorer_path\": \"\",\n",
            "    \"beam_width\": 1024,\n",
            "    \"lm_alpha\": 0.931289039105002,\n",
            "    \"lm_beta\": 1.1834137581510284,\n",
            "    \"cutoff_prob\": 1.0,\n",
            "    \"cutoff_top_n\": 300,\n",
            "    \"one_shot_infer\": null,\n",
            "    \"lm_alpha_max\": 5,\n",
            "    \"lm_beta_max\": 5,\n",
            "    \"n_trials\": 2400\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from coqui_stt_training.util.config import Config\n",
        "# Config.max_to_keep = 10\n",
        "print(Config.to_json())"
      ],
      "id": "cac6ea3d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8e700d1"
      },
      "source": [
        "## ✅ Train a new Marathi model\n",
        "\n",
        "Let's kick off a training run 🚀🚀🚀 (using the configure you set above).\n"
      ],
      "id": "c8e700d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aab2195",
        "scrolled": true,
        "outputId": "c12411d0-53ae-4138-a063-d5420dd3c4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I Performing dummy training to check for memory problems.\n",
            "I If the following process crashes, you likely have batch sizes that are too big for your available system memory (or GPU memory).\n",
            "I Loading best validating checkpoint from english/coqui-yesno-checkpoints/best_dev-1909\n",
            "W CUDNN variable not found: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
            "W CUDNN variable not found: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
            "W CUDNN variable not found: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
            "W CUDNN variable not found: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
            "I Loading variable from checkpoint: beta1_power\n",
            "I Loading variable from checkpoint: beta2_power\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
            "I Loading variable from checkpoint: learning_rate\n",
            "I Initializing variable: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
            "I Initializing variable: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
            "I Initializing variable: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
            "I Initializing variable: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
            "I Initializing variable: layer_6/bias\n",
            "I Initializing variable: layer_6/bias/Adam\n",
            "I Initializing variable: layer_6/bias/Adam_1\n",
            "I Initializing variable: layer_6/weights\n",
            "I Initializing variable: layer_6/weights/Adam\n",
            "I Initializing variable: layer_6/weights/Adam_1\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:00:01 | Steps: 3 | Loss: 542.138163     \n",
            "Epoch 0 | Validation | Elapsed Time: 0:00:01 | Steps: 3 | Loss: 285.885498 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "I FINISHED optimization in 0:00:03.299736\n",
            "I Dummy run finished without problems, now starting real training process.\n",
            "W CUDNN variable not found: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
            "W CUDNN variable not found: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
            "W CUDNN variable not found: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
            "W CUDNN variable not found: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 647.372827     \n",
            "Epoch 0 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 311.251599 | Dataset: ml-data/tgdev.csv\n",
            "I Saved new best validating model with loss 311.251599 to: ml-data/telugu/checkpoints/best_dev-1914\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 359.290005     \n",
            "Epoch 1 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 319.207471 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 269.025323     \n",
            "Epoch 2 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 203.475613 | Dataset: ml-data/tgdev.csv\n",
            "I Saved new best validating model with loss 203.475613 to: ml-data/telugu/checkpoints/best_dev-1924\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 217.112183     \n",
            "Epoch 3 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 204.589551 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 203.372855     \n",
            "Epoch 4 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 213.938806 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 189.355460     \n",
            "Epoch 5 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 206.126303 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 183.488995     \n",
            "Epoch 6 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 214.141901 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 177.638474     \n",
            "Epoch 7 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 217.427328 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 175.146457     \n",
            "Epoch 8 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 211.998416 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 172.246078     \n",
            "Epoch 9 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 215.258694 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 168.825595    \n",
            "Epoch 10 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 207.998260 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 11 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 169.949286    \n",
            "Epoch 11 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 211.528110 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 12 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 169.456882    \n",
            "Epoch 12 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 215.049832 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 13 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 165.185468    \n",
            "Epoch 13 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 213.055194 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 14 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 164.823065    \n",
            "Epoch 14 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 213.175705 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 15 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 163.393143    \n",
            "Epoch 15 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 211.586533 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 16 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 160.888297    \n",
            "Epoch 16 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 207.645825 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 17 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 160.328296    \n",
            "Epoch 17 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 204.725064 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 18 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 159.418829    \n",
            "Epoch 18 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 202.629413 | Dataset: ml-data/tgdev.csv\n",
            "I Saved new best validating model with loss 202.629413 to: ml-data/telugu/checkpoints/best_dev-2004\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 19 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 159.759802    \n",
            "Epoch 19 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 201.100232 | Dataset: ml-data/tgdev.csv\n",
            "I Saved new best validating model with loss 201.100232 to: ml-data/telugu/checkpoints/best_dev-2009\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 20 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 155.931818    \n",
            "Epoch 20 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 199.886517 | Dataset: ml-data/tgdev.csv\n",
            "I Saved new best validating model with loss 199.886517 to: ml-data/telugu/checkpoints/best_dev-2014\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 21 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 157.506238    \n",
            "Epoch 21 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 200.532190 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 22 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 155.837411    \n",
            "Epoch 22 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 202.187085 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 23 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 153.964795    \n",
            "Epoch 23 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 202.677130 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 24 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 153.319769    \n",
            "Epoch 24 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 199.679507 | Dataset: ml-data/tgdev.csv\n",
            "I Saved new best validating model with loss 199.679507 to: ml-data/telugu/checkpoints/best_dev-2034\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 25 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 152.774437    \n",
            "Epoch 25 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 192.600064 | Dataset: ml-data/tgdev.csv\n",
            "I Saved new best validating model with loss 192.600064 to: ml-data/telugu/checkpoints/best_dev-2039\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 26 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 149.729001    \n",
            "Epoch 26 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 188.966003 | Dataset: ml-data/tgdev.csv\n",
            "I Saved new best validating model with loss 188.966003 to: ml-data/telugu/checkpoints/best_dev-2044\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 27 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 147.614590    \n",
            "Epoch 27 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 185.664914 | Dataset: ml-data/tgdev.csv\n",
            "I Saved new best validating model with loss 185.664914 to: ml-data/telugu/checkpoints/best_dev-2049\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 28 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 145.670401    \n",
            "Epoch 28 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 190.359943 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 29 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 144.131194    \n",
            "Epoch 29 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 193.460205 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 30 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 142.910834    \n",
            "Epoch 30 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 197.727640 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 31 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 142.123692    \n",
            "Epoch 31 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 206.218417 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 32 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 141.864026    \n",
            "Epoch 32 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 207.556976 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 33 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 139.876599    \n",
            "Epoch 33 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 200.117279 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 34 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 140.459427    \n",
            "Epoch 34 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 206.305582 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 35 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 138.799397    \n",
            "Epoch 35 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 205.272476 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 36 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 138.689799    \n",
            "Epoch 36 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 205.537180 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 37 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 137.116005    \n",
            "Epoch 37 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 215.494681 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 38 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 136.509924    \n",
            "Epoch 38 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 216.446393 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 39 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 136.058762    \n",
            "Epoch 39 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 213.552957 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 40 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 136.766777    \n",
            "Epoch 40 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 209.654733 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 41 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 137.440115    \n",
            "Epoch 41 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 212.182935 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 42 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 136.079231    \n",
            "Epoch 42 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 213.822803 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 43 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 136.473001    \n",
            "Epoch 43 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 213.125653 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 44 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 133.184831    \n",
            "Epoch 44 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 212.593469 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 45 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 134.395973    \n",
            "Epoch 45 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 213.430936 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 46 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 132.585353    \n",
            "Epoch 46 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 216.927014 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 47 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 131.301947    \n",
            "Epoch 47 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 217.990561 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 48 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 133.780933    \n",
            "Epoch 48 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 213.083429 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 49 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 134.934100    \n",
            "Epoch 49 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 209.381342 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 50 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 133.838988    \n",
            "Epoch 50 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 214.134433 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 51 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 132.954936    \n",
            "Epoch 51 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 216.332156 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 52 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 132.133975    \n",
            "Epoch 52 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 222.531598 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 53 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 130.315669    \n",
            "Epoch 53 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 226.588239 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 54 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 129.380289    \n",
            "Epoch 54 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 226.694882 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 55 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 128.654155    \n",
            "Epoch 55 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 224.122711 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 56 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 128.382295    \n",
            "Epoch 56 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 221.730273 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 57 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 127.013997    \n",
            "Epoch 57 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 222.919611 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 58 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 127.197244    \n",
            "Epoch 58 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 217.773035 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 59 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 126.058589    \n",
            "Epoch 59 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 216.310855 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 60 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 124.534361    \n",
            "Epoch 60 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 215.956921 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 61 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 126.252647    \n",
            "Epoch 61 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 217.143503 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 62 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 124.311813    \n",
            "Epoch 62 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 219.646616 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 63 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 125.536003    \n",
            "Epoch 63 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 223.753601 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 64 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 124.058569    \n",
            "Epoch 64 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 225.133817 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 65 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 123.692017    \n",
            "Epoch 65 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 220.621307 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 66 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 122.944232    \n",
            "Epoch 66 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 222.171225 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 67 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 124.301616    \n",
            "Epoch 67 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 220.028833 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 68 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 121.898138    \n",
            "Epoch 68 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 217.920340 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 69 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 123.410846    \n",
            "Epoch 69 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 219.039731 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 70 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 124.024944    \n",
            "Epoch 70 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 210.430457 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 71 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 123.968326    \n",
            "Epoch 71 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 207.620755 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 72 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 121.746700    \n",
            "Epoch 72 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 223.197128 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 73 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 122.064368    \n",
            "Epoch 73 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 225.187100 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 74 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 120.194197    \n",
            "Epoch 74 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 231.863025 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 75 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 121.647563    \n",
            "Epoch 75 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 224.655994 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 76 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 122.421561    \n",
            "Epoch 76 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 229.519223 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 77 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 128.555757    \n",
            "Epoch 77 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 220.107187 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 78 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 126.951967    \n",
            "Epoch 78 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 210.802423 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 79 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 127.299353    \n",
            "Epoch 79 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 216.538757 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 80 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 125.084404    \n",
            "Epoch 80 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 224.209918 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 81 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 122.008946    \n",
            "Epoch 81 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 226.027338 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 82 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 120.137927    \n",
            "Epoch 82 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 225.806070 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 83 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 120.302524    \n",
            "Epoch 83 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 227.801294 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 84 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 117.251201    \n",
            "Epoch 84 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 221.224628 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 85 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 116.541873    \n",
            "Epoch 85 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 228.163461 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 86 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 119.363043    \n",
            "Epoch 86 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 235.029599 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 87 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 117.291103    \n",
            "Epoch 87 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 227.783258 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 88 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 116.399246    \n",
            "Epoch 88 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 227.074445 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 89 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 116.452953    \n",
            "Epoch 89 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 224.173480 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 90 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 116.029671    \n",
            "Epoch 90 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 227.598892 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 91 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 115.413467    \n",
            "Epoch 91 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 227.284094 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 92 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 113.560051    \n",
            "Epoch 92 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 224.607236 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 93 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 113.445824    \n",
            "Epoch 93 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 224.825537 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 94 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 114.837634    \n",
            "Epoch 94 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 224.957153 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 95 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 115.908041    \n",
            "Epoch 95 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 224.317645 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 96 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 113.091017    \n",
            "Epoch 96 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 227.918146 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 97 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 113.585388    \n",
            "Epoch 97 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 240.412363 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 98 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 113.046030    \n",
            "Epoch 98 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 228.219781 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 99 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 113.269179    \n",
            "Epoch 99 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 235.014957 | Dataset: ml-data/tgdev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "I FINISHED optimization in 0:06:15.285872\n"
          ]
        }
      ],
      "source": [
        "from coqui_stt_training.train import train\n",
        "import os\n",
        "# use maximum one GPU\n",
        "learning_rates = [0.0001]\n",
        "dropout = [0.2,0.4,0.6]\n",
        "spec = [True, False]\n",
        "# Config.epochs = 10\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "# train()\n",
        "# for l in learning_rates:\n",
        "#   for d in dropout:\n",
        "#     for s in spec:\n",
        "#       Config.learning_rate = l\n",
        "#       Config.dropout_rate = d\n",
        "#       Config.augment = [\"frequency_mask[p=0.8, n=2:4, size=2:4]\",\"time_mask[p=0.8, n=2:4, size=10:50, \\\n",
        "#       domain=spectrogram]\"]\n",
        "#       train()\n",
        "#       print(f\"l={l}:::: d = {d}:::: s = {s}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "train()"
      ],
      "id": "8aab2195"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c87ba61"
      },
      "source": [
        "## ✅ Configure the testing run\n",
        "\n",
        "Let's add the path to our testing data and update `load_checkpoint_dir` to our new model checkpoints."
      ],
      "id": "3c87ba61"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6a5c971"
      },
      "source": [
        "## ✅ Test the new Russian model\n",
        "\n",
        "We made it! 🙌\n",
        "\n",
        "Let's kick off the testing run on **training set**, which displays performance metrics.\n"
      ],
      "id": "c6a5c971"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIBvXVDZYISW"
      },
      "source": [
        "Test on **test set**"
      ],
      "id": "fIBvXVDZYISW"
    },
    {
      "cell_type": "code",
      "source": [
        "# f = open('data/ma.csv', 'w')\n",
        "# f.write('wav_filename,wav_filesize,transcript\\n')\n",
        "# f1 = open('data/matest.csv', 'w')\n",
        "# f1.write('wav_filename,wav_filesize,transcript\\n')\n",
        "# f2 = open('data/madev.csv', 'w')\n",
        "# f2.write('wav_filename,wav_filesize,transcript\\n')\n",
        "# with open('data/marathi.tsv', 'r') as rfile:\n",
        "#     lines = rfile.readlines()\n",
        "#     for l in lines[:10]:\n",
        "#         l_ = l.split('\\t')\n",
        "#         f.write('wavs/train/'+l_[0]+'.wav'+',0,'+l_[1])\n",
        "#     # for l in lines[8:10]:\n",
        "#     #     l_ = l.split('\\t')\n",
        "#     #     f2.write('wavs/train/'+l_[0]+'.wav'+',0,'+l_[1])\n",
        "#     for l in lines[10:]:\n",
        "#         l_ = l.split('\\t')\n",
        "#         f1.write('wavs/test/'+l_[0]+'.wav'+',0,'+l_[1])\n",
        "# f.close()\n",
        "# f1.close()\n",
        "# f2.close()\n",
        "f = open('ml-data/kannada.csv','w')\n",
        "f.write('wav_filename,wav_filesize,transcript\\n')\n",
        "f1 = open('ml-data/kdtest.csv', 'w')\n",
        "f1.write('wav_filename,wav_filesize,transcript\\n')\n",
        "f2 = open('ml-data/kddev.csv', 'w')\n",
        "f2.write('wav_filename,wav_filesize,transcript\\n')\n",
        "with open('ml-data/train.tsv', 'r') as rfile:\n",
        "    lines = rfile.readlines()\n",
        "    for l in lines[30:35]:\n",
        "        l_ = l.split('\\t')\n",
        "        f.write('train/kannada/'+l_[0]+'.wav,0,'+l_[1])\n",
        "    for l in lines[35:40]:\n",
        "        l_ = l.split('\\t')\n",
        "        f2.write('train/kannada/'+l_[0]+'.wav,0,'+l_[1])\n",
        "f.close()\n",
        "f1.close()\n",
        "f2.close()"
      ],
      "metadata": {
        "id": "up4gY8_H_MON"
      },
      "id": "up4gY8_H_MON",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft = open('ml-data/kdtest.csv', 'w')\n",
        "ft.write('wav_filename,wav_filesize,transcript\\n')\n",
        "with open('ml-data/test/test.tsv', 'r') as rfile:\n",
        "    lines = rfile.readlines()\n",
        "    for l in lines[:11]:\n",
        "        l_ = l.split('\\t')\n",
        "        ft.write('test/'+l_[0]+'.wav,0,'+l_[1])\n",
        "\n",
        "ft.close()"
      ],
      "metadata": {
        "id": "qVLXt-FA_SLG"
      },
      "id": "qVLXt-FA_SLG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from coqui_stt_training.util.config import initialize_globals_from_args\n",
        "\n",
        "initialize_globals_from_args(\n",
        "    n_hidden=64,\n",
        "    load_checkpoint_dir=\"ml-data/telugu/checkpoints\",\n",
        "    save_checkpoint_dir=\"ml-data/checkpoints\",\n",
        "    drop_source_layers=1,\n",
        "    alphabet_config_path=\"ml-data/kannada-alphabet.txt\",\n",
        "    train_files=[\"ml-data/kannada.csv\"],\n",
        "    dev_files=[\"ml-data/kddev.csv\"],\n",
        "    epochs=100,\n",
        "    load_cudnn=True,\n",
        "    augment = [\"reverb[p=0.1,delay=50.0~30.0,decay=10.0:2.0~1.0]\", \"resample[p=0.1,rate=12000:8000~4000]\", \"codec[p=0.1,bitrate=48000:16000]\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfxAoFD4_ZCi",
        "outputId": "b8864a82-237f-4644-a271-6688d7ef41c3"
      },
      "id": "UfxAoFD4_ZCi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Parsed augmentations: [Reverb(p=0.1, delay=ValueRange(start=50.0, end=50.0, r=30.0), decay=ValueRange(start=10.0, end=2.0, r=1.0)), Resample(p=0.1, rate=ValueRange(start=12000, end=8000, r=4000)), Codec(p=0.1, bitrate=ValueRange(start=48000, end=16000, r=0))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from coqui_stt_training.train import train\n",
        "import os\n",
        "# use maximum one GPU\n",
        "learning_rates = [0.0001]\n",
        "dropout = [0.2,0.4,0.6]\n",
        "spec = [True, False]\n",
        "# Config.epochs = 10\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "# train()\n",
        "# for l in learning_rates:\n",
        "#   for d in dropout:\n",
        "#     for s in spec:\n",
        "#       Config.learning_rate = l\n",
        "#       Config.dropout_rate = d\n",
        "#       Config.augment = [\"frequency_mask[p=0.8, n=2:4, size=2:4]\",\"time_mask[p=0.8, n=2:4, size=10:50, \\\n",
        "#       domain=spectrogram]\"]\n",
        "#       train()\n",
        "#       print(f\"l={l}:::: d = {d}:::: s = {s}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0b1jodS_iLR",
        "outputId": "de157449-2cf1-4851-ffb4-9bc333b12758"
      },
      "id": "g0b1jodS_iLR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I Performing dummy training to check for memory problems.\n",
            "I If the following process crashes, you likely have batch sizes that are too big for your available system memory (or GPU memory).\n",
            "I Loading best validating checkpoint from ml-data/checkpoints/best_dev-2214\n",
            "I Loading variable from checkpoint: beta1_power\n",
            "I Loading variable from checkpoint: beta2_power\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
            "I Loading variable from checkpoint: learning_rate\n",
            "I Initializing variable: layer_6/bias\n",
            "I Initializing variable: layer_6/bias/Adam\n",
            "I Initializing variable: layer_6/bias/Adam_1\n",
            "I Initializing variable: layer_6/weights\n",
            "I Initializing variable: layer_6/weights/Adam\n",
            "I Initializing variable: layer_6/weights/Adam_1\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:00:03 | Steps: 3 | Loss: 303.829681     \n",
            "Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 3 | Loss: 208.879639 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "I FINISHED optimization in 0:00:06.946915\n",
            "I Dummy run finished without problems, now starting real training process.\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:00:05 | Steps: 5 | Loss: 281.597141     \n",
            "Epoch 0 | Validation | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 336.597757 | Dataset: ml-data/kddev.csv\n",
            "I Saved new best validating model with loss 336.597757 to: ml-data/checkpoints/best_dev-2219\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 240.948047     \n",
            "Epoch 1 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 321.868317 | Dataset: ml-data/kddev.csv\n",
            "I Saved new best validating model with loss 321.868317 to: ml-data/checkpoints/best_dev-2224\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 224.547986     \n",
            "Epoch 2 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 335.454562 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 219.888873     \n",
            "Epoch 3 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 331.680960 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 228.728317     \n",
            "Epoch 4 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 332.720615 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 218.194925     \n",
            "Epoch 5 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 335.292023 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 213.923270     \n",
            "Epoch 6 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 334.885440 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 212.515039     \n",
            "Epoch 7 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 338.221811 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 206.610101     \n",
            "Epoch 8 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 334.455060 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 212.983286     \n",
            "Epoch 9 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 336.742657 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 204.026425    \n",
            "Epoch 10 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 339.084534 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 11 |   Training | Elapsed Time: 0:00:04 | Steps: 5 | Loss: 202.834158    \n",
            "Epoch 11 | Validation | Elapsed Time: 0:00:04 | Steps: 5 | Loss: 341.730600 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 12 |   Training | Elapsed Time: 0:00:04 | Steps: 5 | Loss: 203.279114    \n",
            "Epoch 12 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 343.100751 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 13 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 199.107623    \n",
            "Epoch 13 | Validation | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 344.341174 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 14 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 198.520236    \n",
            "Epoch 14 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 344.033078 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 15 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 196.008063    \n",
            "Epoch 15 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 345.429990 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 16 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 197.438110    \n",
            "Epoch 16 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 344.879272 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 17 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 196.283078    \n",
            "Epoch 17 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 348.071259 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 18 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 206.258292    \n",
            "Epoch 18 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 351.144342 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 19 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 193.428943    \n",
            "Epoch 19 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 341.741153 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 20 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 191.925082    \n",
            "Epoch 20 | Validation | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 344.366855 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 21 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 192.574786    \n",
            "Epoch 21 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 356.860336 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 22 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 191.755530    \n",
            "Epoch 22 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 349.096829 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 23 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 195.779709    \n",
            "Epoch 23 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 359.585507 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 24 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 196.308533    \n",
            "Epoch 24 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 362.253238 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 25 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 197.003357    \n",
            "Epoch 25 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 352.021701 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 26 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 195.821793    \n",
            "Epoch 26 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 350.523694 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 27 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 204.130032    \n",
            "Epoch 27 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 376.322910 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 28 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 263.034598    \n",
            "Epoch 28 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 378.432434 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 29 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 240.753842    \n",
            "Epoch 29 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 381.557855 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 30 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 218.861688    \n",
            "Epoch 30 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 352.218030 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 31 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 212.744095    \n",
            "Epoch 31 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 343.343655 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 32 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 210.185010    \n",
            "Epoch 32 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 354.563867 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 33 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 220.472079    \n",
            "Epoch 33 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 341.453882 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 34 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 219.194418    \n",
            "Epoch 34 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 349.950482 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 35 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 202.841571    \n",
            "Epoch 35 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 387.110455 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 36 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 205.526459    \n",
            "Epoch 36 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 361.889182 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 37 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 229.346829    \n",
            "Epoch 37 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 354.692255 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 38 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 218.549591    \n",
            "Epoch 38 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 352.216815 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 39 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 200.011029    \n",
            "Epoch 39 | Validation | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 359.998428 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 40 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 206.860501    \n",
            "Epoch 40 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 342.187039 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 41 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 201.775186    \n",
            "Epoch 41 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 333.052768 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 42 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 224.382401    \n",
            "Epoch 42 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 338.409528 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 43 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 197.680316    \n",
            "Epoch 43 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 357.606628 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 44 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 200.644440    \n",
            "Epoch 44 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 352.785596 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 45 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 199.987500    \n",
            "Epoch 45 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 340.987955 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 46 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 196.321625    \n",
            "Epoch 46 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 345.487988 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 47 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 192.032938    \n",
            "Epoch 47 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 352.838257 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 48 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 194.252554    \n",
            "Epoch 48 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 352.315863 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 49 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 191.555539    \n",
            "Epoch 49 | Validation | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 349.881522 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 50 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 207.600183    \n",
            "Epoch 50 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 358.692926 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 51 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 191.126776    \n",
            "Epoch 51 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 388.218719 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 52 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 195.657346    \n",
            "Epoch 52 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 381.353778 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 53 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 209.443768    \n",
            "Epoch 53 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 352.255115 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 54 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 199.810724    \n",
            "Epoch 54 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 353.604654 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 55 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 198.929172    \n",
            "Epoch 55 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 358.447360 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 56 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 199.467764    \n",
            "Epoch 56 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 355.396017 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 57 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 198.784219    \n",
            "Epoch 57 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 347.766013 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 58 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 196.702682    \n",
            "Epoch 58 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 346.671298 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 59 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 194.499194    \n",
            "Epoch 59 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 344.289978 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 60 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 188.834445    \n",
            "Epoch 60 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 345.944684 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 61 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 198.146393    \n",
            "Epoch 61 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 347.613672 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 62 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 190.336786    \n",
            "Epoch 62 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 348.626450 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 63 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 190.027859    \n",
            "Epoch 63 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 349.628229 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 64 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 191.775195    \n",
            "Epoch 64 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 351.957053 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 65 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 206.512216    \n",
            "Epoch 65 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 352.804016 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 66 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 189.484332    \n",
            "Epoch 66 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 351.469772 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 67 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 193.700824    \n",
            "Epoch 67 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 352.425943 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 68 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 187.990436    \n",
            "Epoch 68 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 356.358386 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 69 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 188.437811    \n",
            "Epoch 69 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 358.662213 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 70 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 189.628931    \n",
            "Epoch 70 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 354.847382 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 71 |   Training | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 191.232968    \n",
            "Epoch 71 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 353.353860 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 72 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 210.067880    \n",
            "Epoch 72 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 360.887671 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 73 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 186.775873    \n",
            "Epoch 73 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 399.399335 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 74 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 197.716647    \n",
            "Epoch 74 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 395.466638 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 75 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 190.538843    \n",
            "Epoch 75 | Validation | Elapsed Time: 0:00:03 | Steps: 5 | Loss: 375.709238 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 76 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 188.282532    \n",
            "Epoch 76 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 372.149323 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 77 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 183.786246    \n",
            "Epoch 77 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 389.450433 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 78 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 183.847708    \n",
            "Epoch 78 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 428.569476 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 79 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 189.989838    \n",
            "Epoch 79 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 371.748618 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 80 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 194.205453    \n",
            "Epoch 80 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 378.468152 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 81 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 230.791068    \n",
            "Epoch 81 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 392.642389 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 82 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 186.334634    \n",
            "Epoch 82 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 373.911093 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 83 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 200.656116    \n",
            "Epoch 83 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 379.349524 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 84 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 185.949741    \n",
            "Epoch 84 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 404.146387 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 85 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 188.634283    \n",
            "Epoch 85 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 370.864752 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 86 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 213.964783    \n",
            "Epoch 86 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 371.002060 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 87 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 212.481735    \n",
            "Epoch 87 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 422.046521 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 88 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 198.451675    \n",
            "Epoch 88 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 454.570032 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 89 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 200.068109    \n",
            "Epoch 89 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 365.872269 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 90 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 191.627655    \n",
            "Epoch 90 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 351.737997 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 91 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 190.281912    \n",
            "Epoch 91 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 355.026489 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 92 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 181.816531    \n",
            "Epoch 92 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 363.798331 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 93 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 183.772443    \n",
            "Epoch 93 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 383.183771 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 94 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 181.525281    \n",
            "Epoch 94 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 369.169821 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 95 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 224.076254    \n",
            "Epoch 95 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 357.304248 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 96 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 181.230142    \n",
            "Epoch 96 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 352.794519 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 97 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 178.899637    \n",
            "Epoch 97 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 351.960931 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 98 |   Training | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 179.734766    \n",
            "Epoch 98 | Validation | Elapsed Time: 0:00:01 | Steps: 5 | Loss: 365.100989 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 99 |   Training | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 175.509293    \n",
            "Epoch 99 | Validation | Elapsed Time: 0:00:02 | Steps: 5 | Loss: 380.734280 | Dataset: ml-data/kddev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "I FINISHED optimization in 0:08:46.366501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from coqui_stt_training.util.config import Config\n",
        "\n",
        "Config.test_files=[\"ml-data/kdtest.csv\"]\n",
        "Config.load_checkpoint_dir=\"ml-data/checkpoints\""
      ],
      "metadata": {
        "id": "JfvFE4Dr_rEx"
      },
      "id": "JfvFE4Dr_rEx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from coqui_stt_training.evaluate import test\n",
        "\n",
        "test()"
      ],
      "metadata": {
        "id": "OjC-DRcP_vAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc3455b-2add-463e-9da0-3ab6402ee9d2"
      },
      "id": "OjC-DRcP_vAo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I Loading best validating checkpoint from ml-data/checkpoints/best_dev-2224\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "Testing model on ml-data/kdtest.csv\n",
            "Test epoch | Steps: 10 | Elapsed Time: 0:01:29                                 \n",
            "Test on ml-data/kdtest.csv - WER: 1.000000, CER: 0.853377, loss: 292.490570\n",
            "--------------------------------------------------------------------------------\n",
            "Best WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.827586, loss: 403.203735\n",
            " - wav: file://ml-data/test/knf_00254_01541969378.wav\n",
            " - src: \"ಸರ್ಕಾರದ ಖಜಾನೆಯ ಇಷ್ಟಾನುಸಾರವಾಗಿ ಹೆಚ್ಚು ವ್ಯಾಪಕವಾದ ಬಹಿರಂಗಪಡಿಸುವಿಕೆಯ ಅವಶ್ಯಕತೆಯು ಕಂಡುಬರಬಹುದು.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ನ್ಿರುರುರುರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.816092, loss: 382.694092\n",
            " - wav: file://ml-data/test/knf_06123_01599183050.wav\n",
            " - src: \"ಗ್ರಾಮದಲ್ಲಿ ಫಲವತ್ತಾದ ಭೂಮಿ ಇರುವುದರಿಂದ ಎಪ್ಪತ್ತು ಪ್ರತಿಶತ ಜನಸಂಖ್ಯೆ ಕೃಷಿಯಲ್ಲಿ ನಿರತರಾಗಿದ್ದಾರೆ.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ಿರ ರುರುರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.865385, loss: 378.092987\n",
            " - wav: file://ml-data/test/knf_00254_01445391292.wav\n",
            " - src: \"ಅಲ್ಲದೇ ಅವುಗಳನ್ನು ಅಲ್ಲಿನ ಅಡುಗೆ ಮನೆಯಲ್ಲಿ ಬೇಯಿಸುತ್ತಾರೆ.\"\n",
            " - res: \"್ರ್ರ್ರ್ಿರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.883117, loss: 365.116974\n",
            " - wav: file://ml-data/test/knf_05550_01207101906.wav\n",
            " - src: \"ಅಮೃತಮಂಥನದಲ್ಲಿ ಧನ್ವಂತರಿ ಹುಟ್ಟಿ ಲೋಕಕ್ಕೆ ಅಮೃತವನ್ನು ತಂದನೆಂದು ಮಹಾಭಾರತದಲ್ಲಿ ಹೇಳಿದೆ.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ರ ರ ರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.927273, loss: 299.973785\n",
            " - wav: file://ml-data/test/knf_01779_02024713720.wav\n",
            " - src: \"ಅಂತರಜಾಲ ಸೌಲಭ್ಯ ಇಲ್ಲದವರಿಗೆ ಅಂತಾರಾಷ್ಟ್ರೀಯ ಧನಾದೇಶ ಸ್ವೀಕೃತಿ\"\n",
            " - res: \"ರುರುರುರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "Median WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.883117, loss: 365.116974\n",
            " - wav: file://ml-data/test/knf_05550_01207101906.wav\n",
            " - src: \"ಅಮೃತಮಂಥನದಲ್ಲಿ ಧನ್ವಂತರಿ ಹುಟ್ಟಿ ಲೋಕಕ್ಕೆ ಅಮೃತವನ್ನು ತಂದನೆಂದು ಮಹಾಭಾರತದಲ್ಲಿ ಹೇಳಿದೆ.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ರ ರ ರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.927273, loss: 299.973785\n",
            " - wav: file://ml-data/test/knf_01779_02024713720.wav\n",
            " - src: \"ಅಂತರಜಾಲ ಸೌಲಭ್ಯ ಇಲ್ಲದವರಿಗೆ ಅಂತಾರಾಷ್ಟ್ರೀಯ ಧನಾದೇಶ ಸ್ವೀಕೃತಿ\"\n",
            " - res: \"ರುರುರುರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.878788, loss: 291.155640\n",
            " - wav: file://ml-data/test/knf_09696_02009165869.wav\n",
            " - src: \"ಹವಾಮಾನ ಅನನಕೂಲವಾಗಿದ್ದರೆ ಇವುಗಳನ್ನು ಒಂದು ದಿನದಲ್ಲಿ ಪೂರ್ಣಗೊಳಿಸುವುದಿಲ್ಲ.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ ರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.848485, loss: 253.178619\n",
            " - wav: file://ml-data/test/knf_09696_00779393186.wav\n",
            " - src: \"ಈ ವ್ಯವಹಾರ ಶಿಕ್ಷಣ ವಂತರಿಗೆ ಮಾತ್ರ ಸಾಧ್ಯ ಅವಿಧ್ಯಾವಂತರಿಗೆ ಇದು ಸೂಕ್ತವಲ್ಲ.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ನ್ನ್ಿರುರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.777778, loss: 236.520523\n",
            " - wav: file://ml-data/test/knf_01779_02006639329.wav\n",
            " - src: \"ಪುರಾಣಗಳಲ್ಲಿ ಬ್ರಹ್ಮನೇ ಆಯುರ್ವೇದಕ್ಕೆ ಮೂಲ ಎಂದಿದೆ.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ಿರ ರ ರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "Worst WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.878788, loss: 291.155640\n",
            " - wav: file://ml-data/test/knf_09696_02009165869.wav\n",
            " - src: \"ಹವಾಮಾನ ಅನನಕೂಲವಾಗಿದ್ದರೆ ಇವುಗಳನ್ನು ಒಂದು ದಿನದಲ್ಲಿ ಪೂರ್ಣಗೊಳಿಸುವುದಿಲ್ಲ.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ ರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.848485, loss: 253.178619\n",
            " - wav: file://ml-data/test/knf_09696_00779393186.wav\n",
            " - src: \"ಈ ವ್ಯವಹಾರ ಶಿಕ್ಷಣ ವಂತರಿಗೆ ಮಾತ್ರ ಸಾಧ್ಯ ಅವಿಧ್ಯಾವಂತರಿಗೆ ಇದು ಸೂಕ್ತವಲ್ಲ.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ನ್ನ್ಿರುರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.777778, loss: 236.520523\n",
            " - wav: file://ml-data/test/knf_01779_02006639329.wav\n",
            " - src: \"ಪುರಾಣಗಳಲ್ಲಿ ಬ್ರಹ್ಮನೇ ಆಯುರ್ವೇದಕ್ಕೆ ಮೂಲ ಎಂದಿದೆ.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ಿರ ರ ರುರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.833333, loss: 191.910583\n",
            " - wav: file://ml-data/test/knf_06123_00368408007.wav\n",
            " - src: \"ಇದರ ಜೊತೆಗೆ ನೀರಿನ ಮರುಪೂರಣೆ ಸಮರ್ಪಕವಾಗಿ ಆಗುತ್ತಿಲ್ಲ.\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ ್ಿ್ಿರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.916667, loss: 123.058884\n",
            " - wav: file://ml-data/test/knf_05550_01010202503.wav\n",
            " - src: \"ಅಂತರಿಕ್ಷಯಾನ ಇಂಜಿನಿಯರುಗಳು\"\n",
            " - res: \"್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ್ರ ರುರುರ\"\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FFQPVp6CM2ql"
      },
      "id": "FFQPVp6CM2ql",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Task2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}